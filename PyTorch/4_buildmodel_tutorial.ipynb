{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bioinfo-gao/LLM/blob/main/PyTorch/4_buildmodel_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vk_6f0q94Z10"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://docs.pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLou8gp_4Z12"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\|\n",
        "[Quickstart](quickstart_tutorial.html) \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| **Build Model** \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Build the Neural Network\n",
        "========================\n",
        "\n",
        "Neural networks comprise of layers/modules that perform operations on\n",
        "data. The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace\n",
        "provides all the building blocks you need to build your own neural\n",
        "network. Every module in PyTorch subclasses the\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "A neural network is a module itself that consists of other modules\n",
        "(layers). This nested structure allows for building and managing complex\n",
        "architectures easily.\n",
        "\n",
        "In the following sections, we\\'ll build a neural network to classify\n",
        "images in the FashionMNIST dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tZQXknZm4Z13"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c509N7JR4Z14"
      },
      "source": [
        "<font color=\"red\"> Get Device for Training\n",
        "=======================\n",
        "\n",
        "We want to be able to train our model on an\n",
        "[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
        "such as <font color=\" blue\"> CUDA, MPS, MTIA, or XPU. </font> If the current accelerator is\n",
        "available, we will use it. Otherwise, we use the CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k2aleXpk4Z14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba637c3-c75f-40b5-a129-dec60ac14856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP03oGQj4Z14"
      },
      "source": [
        "Define the Class\n",
        "================\n",
        "\n",
        "We define our neural network by <font color=\" blue\">subclassing `nn.Module` </font>, and initialize\n",
        "the neural network layers in `__init__`. <font color=\" red\"> Every `nn.Module` subclass\n",
        "</font>implements the operations on input data in <font color=\" green\"> the `forward` method. </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "50K_3HaO4Z15"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # Every nn.Module subclass implements forward method for input data\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orgQs0R74Z15"
      },
      "source": [
        "We create an instance of `NeuralNetwork`, and move it to the <font color=\" red\"> `device` </font>,\n",
        "and print its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uHwLrpa74Z15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2344f7af-d223-45c5-e58a-8bee4c5cf70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVqEbC_24Z15"
      },
      "source": [
        "To use the model, we pass it the input data. This executes the model\\'s\n",
        "`forward`, along with some [background\n",
        "operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n",
        "<font color=\" red\"> Do not call `model.forward()` directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with dim=0\n",
        "corresponding to each output of 10 raw predicted values for each class,\n",
        "and dim=1 corresponding to the individual values of each output. We get\n",
        "the prediction probabilities by passing it through an instance of the\n",
        "`nn.Softmax` module.\n",
        "\n",
        "\n",
        "è¿™æ®µè¯æè¿°çš„æ¨¡å‹è¾“å‡ºæ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡ï¼ˆ2D Tensorï¼‰ï¼Œå…¶å½¢çŠ¶é€šå¸¸è¡¨ç¤ºä¸º (æ‰¹æ¬¡å¤§å° $\\times$ ç±»åˆ«æ•°)ã€‚\n",
        "\n",
        "\n",
        "1. dim=0 (è¡Œ): æ‰¹æ¬¡ç»´åº¦\n",
        "\n",
        "å¯¹åº”ï¼šdim=0 å¯¹åº”äºæ¯ä¸ªè¾“å‡ºï¼Œå³æ‰¹æ¬¡ (Batch) ä¸­çš„æ¯ä¸ªç‹¬ç«‹æ ·æœ¬/å›¾ç‰‡ã€‚  \n",
        "\n",
        "ç¤ºä¾‹ï¼š å¦‚æœ dim=0 çš„å¤§å°æ˜¯ 64ï¼Œè¡¨ç¤ºæ‚¨åŒæ—¶å‘æ¨¡å‹è¾“å…¥äº† 64 å¼ å›¾ç‰‡æˆ–æ•°æ®æ ·æœ¬ã€‚  \n",
        "\n",
        "2. dim=1 (åˆ—): ç±»åˆ«ç»´åº¦\n",
        "\n",
        "å¯¹åº”ï¼š dim=1 å¯¹åº”äºæ¯ä¸ªè¾“å‡ºçš„ä¸ªä½“å€¼ï¼Œå³æ¯ä¸ªç±»åˆ«å¯¹åº”çš„åŸå§‹é¢„æµ‹å€¼ã€‚  \n",
        "\n",
        "ç¤ºä¾‹ï¼š æ–‡ä¸­æåˆ° 10 ä¸ªåŸå§‹é¢„æµ‹å€¼ï¼Œæ„å‘³ç€è¿™æ˜¯ä¸€ä¸ª**10 åˆ†ç±»é—®é¢˜**ã€‚å¯¹äºæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬ï¼Œæ¨¡å‹éƒ½ä¼šç»™å‡ºä¸€ä¸ªé•¿åº¦ä¸º 10 çš„åŸå§‹åˆ†æ•°å‘é‡ã€‚\n",
        "\n",
        "åŸå§‹å€¼æ€§è´¨ï¼š è¿™äº›åŸå§‹å€¼è¢«ç§°ä¸º Logitsï¼ˆå¯¹æ•°å‡ ç‡ï¼‰ï¼Œå®ƒä»¬æ˜¯æ— ç•Œçš„ï¼ˆå¯ä»¥æ˜¯è´Ÿæ•°ã€é›¶æˆ–æ­£æ•°ï¼‰ï¼Œå¹¶ä¸”ä¸æ±‚å’Œä¸º 1ã€‚\n",
        "\n",
        "\n",
        "\n",
        "ä¸ºäº†å°†è¿™äº›åŸå§‹åˆ†æ•° $\\text{Logits}$ è½¬åŒ–ä¸ºæ¦‚ç‡ ($\\text{Probabilities}$)ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ $\\text{nn.Softmax}$ æ¨¡å—ã€‚\n",
        "\n",
        "1. è½¬æ¢ç›®çš„$\\text{Softmax}$ å‡½æ•°æ‰§è¡Œå½’ä¸€åŒ–ï¼šæ¦‚ç‡åŒ–ï¼š å°† $\\text{Logits}$ æ˜ å°„åˆ° $\\text{[0, 1]}$ çš„åŒºé—´ã€‚æ€»å’Œä¸º 1ï¼š ç¡®ä¿åŒä¸€ç»´åº¦ï¼ˆå³æ‰€æœ‰ç±»åˆ«ï¼‰çš„æ¦‚ç‡æ€»å’Œä¸º $\\text{1}$ã€‚è¿™ä½¿å¾—æ‚¨å¯ä»¥å°†è¾“å‡ºè§£é‡Šä¸ºæ¨¡å‹å¯¹æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦ã€‚\n",
        "\n",
        "2. æ•°å­¦åŸºç¡€$\\text{Softmax}$ å‡½æ•°é€šè¿‡æŒ‡æ•°åŒ–å¹¶é™¤ä»¥æ€»å’Œæ¥å®ç°å½’ä¸€åŒ–ã€‚å¯¹äºè¾“å‡ºå‘é‡ $\\mathbf{z}$ ä¸­çš„ç¬¬ $i$ ä¸ªå…ƒç´  $z_i$ï¼Œå…¶ $\\text{Softmax}$ ç»“æœ $p_i$ ä¸ºï¼š$$p_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
        "\n",
        "3. åº”ç”¨ç»´åº¦ (Crucial Dimension)å½“æ‚¨åœ¨ $\\text{PyTorch}$ ä¸­ä½¿ç”¨ $\\text{nn.Softmax}$ æ—¶ï¼Œæ‚¨å¿…é¡»æŒ‡å®šä½œç”¨çš„ç»´åº¦ã€‚æ­£ç¡®åšæ³•ï¼š $\\text{Softmax}$ å¿…é¡»ä½œç”¨äº $\\text{dim}=1$ï¼ˆå³ç±»åˆ«ç»´åº¦ï¼‰ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PmOoXPRq4Z16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e51f40-e288-4e30-e957-3cc71bf5054b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([3], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X) # model output ï¼ <<<====================================\n",
        "\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk2pEkfY4Z16"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU7Nq9Vf4Z16"
      },
      "source": [
        "Model Layers\n",
        "============\n",
        "\n",
        "Let\\'s break down the layers in the FashionMNIST model. To illustrate\n",
        "it, we will take a sample minibatch of <font color=\" red\">  3 images of size 28x28 </font> and see\n",
        "what happens to it as we pass it through the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4hbr_Wa04Z16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83a5c26-e473-4bb2-80af-57fd3ade14ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW2mQiGd4Z16"
      },
      "source": [
        "nn.Flatten\n",
        "==========\n",
        "\n",
        "We initialize the\n",
        "[nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
        "layer to convert each 2D 28x28 image into a contiguous array of 784\n",
        "pixel values ( the minibatch dimension (at dim=0) is maintained).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QGOfOj-04Z16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9776e96-507a-4682-8884-90ddbe97106c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8mGvpCI4Z16"
      },
      "source": [
        "nn.Linear\n",
        "=========\n",
        "\n",
        "The [linear\n",
        "layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "is a module that applies a linear transformation on the input using its\n",
        "stored weights and biases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-N7c79Uf4Z17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d559b3-98b0-4622-9144-f451eb50b68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84mIjXly4Z17"
      },
      "source": [
        "nn.ReLU\n",
        "=======\n",
        "\n",
        "Non-linear activations are what create the complex mappings between the\n",
        "model\\'s inputs and outputs. They are applied after linear\n",
        "transformations to introduce *nonlinearity*, helping neural networks\n",
        "learn a wide variety of phenomena.\n",
        "\n",
        "In this model, we use\n",
        "[nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "between our linear layers, but there\\'s other activations to introduce\n",
        "non-linearity in your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rHMrvVi04Z17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54859d08-05b2-4fbe-992d-242a21452309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1275,  0.1048, -0.4153,  0.7854,  0.2479,  0.0022, -0.0528,  0.2747,\n",
            "          0.0106, -0.7177, -0.5073, -0.2946,  0.3168, -0.1310,  0.4564, -0.5561,\n",
            "          0.1361, -0.0796,  0.0641,  0.2655],\n",
            "        [ 0.1759,  0.4547, -0.8307,  0.4997,  0.0839, -0.2091, -0.0277,  0.0675,\n",
            "          0.0167, -0.4265, -0.5054,  0.1311,  0.4294, -0.5734,  0.4059, -0.4835,\n",
            "          0.1121, -0.2282, -0.0095,  0.2411],\n",
            "        [-0.2416,  0.1318, -0.5253,  0.1219,  0.3698, -0.2199, -0.1411,  0.1202,\n",
            "         -0.3719, -0.6189, -0.1769,  0.0453, -0.2176, -0.3937,  0.1943, -0.5890,\n",
            "         -0.1260, -0.1086, -0.0094,  0.2459]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1275, 0.1048, 0.0000, 0.7854, 0.2479, 0.0022, 0.0000, 0.2747, 0.0106,\n",
            "         0.0000, 0.0000, 0.0000, 0.3168, 0.0000, 0.4564, 0.0000, 0.1361, 0.0000,\n",
            "         0.0641, 0.2655],\n",
            "        [0.1759, 0.4547, 0.0000, 0.4997, 0.0839, 0.0000, 0.0000, 0.0675, 0.0167,\n",
            "         0.0000, 0.0000, 0.1311, 0.4294, 0.0000, 0.4059, 0.0000, 0.1121, 0.0000,\n",
            "         0.0000, 0.2411],\n",
            "        [0.0000, 0.1318, 0.0000, 0.1219, 0.3698, 0.0000, 0.0000, 0.1202, 0.0000,\n",
            "         0.0000, 0.0000, 0.0453, 0.0000, 0.0000, 0.1943, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.2459]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me62c24T4Z17"
      },
      "source": [
        "nn.Sequential\n",
        "=============\n",
        "\n",
        "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "is an ordered container of modules. The data is passed through all the\n",
        "modules in the same order as defined. You can use sequential containers\n",
        "to put together a quick network like `seq_modules`.\n",
        "\n",
        "$\\text{nn.Sequential}$ æ˜¯ä¸€ç§ç»„ç»‡ç¥ç»ç½‘ç»œå±‚çš„æ–¹å¼ï¼Œå®ƒæŠŠä¸€ç³»åˆ—æ“ä½œï¼ˆæ¨¡å—ï¼‰æŒ‰é¡ºåºæ‰“åŒ…æˆä¸€ä¸ªå•ä¸€çš„æ¨¡å—ï¼Œè®©æ•°æ®å¯ä»¥åƒæµæ°´çº¿ä¸€æ ·é€šè¿‡å®ƒä»¬ã€‚\n",
        "\n",
        "ğŸ—ï¸ nn.Sequential è§£é‡Š\n",
        "\n",
        "1. æœ‰åºå®¹å™¨ (Ordered Container)æ¦‚å¿µï¼š $\\text{nn.Sequential}$ å°±åƒä¸€ä¸ªåˆ—è¡¨æˆ–æ•°ç»„ï¼Œå®ƒæŒ‰ç…§æ‚¨å®šä¹‰çš„é¡ºåºä¸¥æ ¼åœ°å®¹çº³å¤šä¸ªç‹¬ç«‹çš„ç½‘ç»œå±‚ï¼ˆæ¨¡å—ï¼Œå¦‚ $\\text{nn.Linear}$ã€$\\text{nn.Conv2d}$ã€$\\text{nn.ReLU}$ ç­‰ï¼‰ã€‚ä½œç”¨ï¼š å®ƒçš„ä¸»è¦ç›®çš„æ˜¯ç»“æ„åŒ–å’Œç®€åŒ–ç¥ç»ç½‘ç»œçš„æ„å»ºè¿‡ç¨‹ã€‚\n",
        "\n",
        "2. æ•°æ®æµ (Data Flow)æœºåˆ¶ï¼š æ•°æ®æ˜¯æŒ‰ç…§å®šä¹‰çš„ç›¸åŒé¡ºåºä¾æ¬¡é€šè¿‡æ‰€æœ‰æ¨¡å—çš„ã€‚è¿‡ç¨‹ï¼šè¾“å…¥æ•°æ®è¿›å…¥ $\\text{Sequential}$ å®¹å™¨ä¸­çš„ ç¬¬ä¸€ä¸ªæ¨¡å—ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—çš„è¾“å‡ºä½œä¸º ç¬¬äºŒä¸ªæ¨¡å— çš„è¾“å…¥ã€‚è¿™ä¸ªè¿‡ç¨‹é‡å¤è¿›è¡Œï¼Œç›´åˆ°æ•°æ®é€šè¿‡å®¹å™¨ä¸­çš„æ‰€æœ‰æ¨¡å—ã€‚ç®€æ´æ€§ï¼š å®ƒå°†åŸæ¥éœ€è¦å¤šè¡Œä»£ç å®šä¹‰çš„å‰å‘ä¼ æ’­ ($\\text{forward}$) é€»è¾‘ï¼ˆä¾‹å¦‚ x = layer1(x); x = layer2(x); x = activation(x)ï¼‰ç®€åŒ–ä¸ºä¸€è¡Œä»£ç ï¼šoutput = seq_modules(input)ã€‚\n",
        "\n",
        "3. æ„å»ºå¿«é€Ÿç½‘ç»œ (Quick Network)ç¤ºä¾‹ï¼š å°±åƒæ‚¨æåˆ°çš„ seq_modulesï¼Œ$\\text{nn.Sequential}$ æœ€å¸¸ç”¨äºæ„å»ºç®€å•ã€å‰é¦ˆï¼ˆ$\\text{Feed-forward}$ï¼‰ç»“æ„çš„ç½‘ç»œã€‚ä»£ç ç¤ºä¾‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential ç¤ºä¾‹ï¼Œ æˆ‘ä¸ªäººçš„è®°å¿†è¿™å°±æ˜¯Tensorflow å’Œ PyTorchçš„åŒºåˆ«\n",
        "import torch.nn as nn\n",
        "\n",
        "# ä¼ ç»Ÿæ–¹å¼éœ€è¦è‡ªå·±å®šä¹‰ forward()\n",
        "# class SimpleNet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         self.layer1 = nn.Linear(784, 128)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.layer2 = nn.Linear(128, 10)\n",
        "#     def forward(self, x):\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.layer2(x)\n",
        "#         return x\n",
        "\n",
        "# ä½¿ç”¨ nn.Sequential (æ›´ç®€æ´)\n",
        "seq_modules = nn.Sequential(\n",
        "    nn.Linear(784, 128),  # æ¨¡å— 1\n",
        "    nn.ReLU(),            # æ¨¡å— 2\n",
        "    nn.Linear(128, 10)    # æ¨¡å— 3\n",
        ")\n",
        "\n",
        "# æ•°æ®è¾“å…¥ï¼šoutput = seq_modules(input)"
      ],
      "metadata": {
        "id": "PniBo27FI4Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QJXr7lgh4Z17"
      },
      "outputs": [],
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkdU33qF4Z17"
      },
      "source": [
        "nn.Softmax\n",
        "==========\n",
        "\n",
        "The last linear layer of the neural network returns [logits]{.title-ref}\n",
        "- raw values in \\[-infty, infty\\] - which are passed to the\n",
        "[nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)\n",
        "module. The logits are scaled to values \\[0, 1\\] representing the\n",
        "model\\'s predicted probabilities for each class. `dim` parameter\n",
        "indicates the dimension along which the values must sum to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HJdlr1_z4Z17"
      },
      "outputs": [],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfrjm-Qw4Z17"
      },
      "source": [
        "Model Parameters\n",
        "================\n",
        "\n",
        "Many layers inside a neural network are *parameterized*, i.e. have\n",
        "associated weights and biases that are optimized during training.\n",
        "Subclassing `nn.Module` automatically tracks all fields defined inside\n",
        "your model object, and makes all parameters accessible using your\n",
        "model\\'s `parameters()` or `named_parameters()` methods.\n",
        "\n",
        "In this example, we iterate over each parameter, and print its size and\n",
        "a preview of its values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gsAx2TVn4Z17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3261df4e-57ae-4ef0-dc3a-370f2c41883e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0178, -0.0316,  0.0056,  ...,  0.0188,  0.0069, -0.0246],\n",
            "        [ 0.0121, -0.0231, -0.0181,  ...,  0.0172, -0.0071, -0.0151]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0210, -0.0172], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0294, -0.0356,  0.0176,  ..., -0.0117, -0.0129,  0.0258],\n",
            "        [-0.0267,  0.0015, -0.0097,  ...,  0.0387, -0.0131, -0.0306]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0344,  0.0382], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0038, -0.0214, -0.0397,  ...,  0.0382, -0.0268, -0.0190],\n",
            "        [ 0.0407,  0.0222,  0.0078,  ...,  0.0125,  0.0127,  0.0395]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0016, -0.0379], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2B8BHlw4Z17"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcsNF12J4Z18"
      },
      "source": [
        "Further Reading\n",
        "===============\n",
        "\n",
        "-   [torch.nn API](https://pytorch.org/docs/stable/nn.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}